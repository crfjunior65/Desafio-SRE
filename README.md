# ğŸš€ Desafio SRE - ElvenWorks

## ğŸ“‹ Sobre o Projeto

Projeto desenvolvido como parte do Nivelamento Tecnico e processo de InclusÃ£o na Equipe para a posiÃ§Ã£o de SRE / DevOps na Elvenworks. O desafio consiste em implementar uma stack completa de DevOps/SRE, desde a containerizaÃ§Ã£o de uma aplicaÃ§Ã£o atÃ© o deploy em Kubernetes com monitoramento completo.

## ğŸ› ï¸ Tecnologias Implementadas nos Desafios

### **AplicaÃ§Ã£o & Runtime**
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Flask](https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white)
![Gunicorn](https://img.shields.io/badge/Gunicorn-499848?style=for-the-badge&logo=gunicorn&logoColor=white)

### **ContainerizaÃ§Ã£o & OrquestraÃ§Ã£o**
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white)
![Kind](https://img.shields.io/badge/Kind-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white)

### **Cloud & Infraestrutura**
![AWS](https://img.shields.io/badge/AWS-FF9900?style=for-the-badge&logo=amazon-aws&logoColor=white)
![Terraform](https://img.shields.io/badge/Terraform-623CE4?style=for-the-badge&logo=terraform&logoColor=white)
![Amazon EKS](https://img.shields.io/badge/Amazon_EKS-FF9900?style=for-the-badge&logo=amazon-eks&logoColor=white)
![Amazon RDS](https://img.shields.io/badge/Amazon_RDS-527FFF?style=for-the-badge&logo=amazon-rds&logoColor=white)
![Amazon ElastiCache](https://img.shields.io/badge/ElastiCache-FF9900?style=for-the-badge&logo=amazon-aws&logoColor=white)

### **Bancos de Dados & Cache**
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)
![Redis](https://img.shields.io/badge/Redis-DC382D?style=for-the-badge&logo=redis&logoColor=white)
![OpenSearch](https://img.shields.io/badge/OpenSearch-005EB8?style=for-the-badge&logo=opensearch&logoColor=white)
![Elasticsearch](https://img.shields.io/badge/Elasticsearch-005571?style=for-the-badge&logo=elasticsearch&logoColor=white)

### **Messaging & Streaming**
![Apache Kafka](https://img.shields.io/badge/Apache_Kafka-231F20?style=for-the-badge&logo=apache-kafka&logoColor=white)
![Amazon MSK](https://img.shields.io/badge/Amazon_MSK-FF9900?style=for-the-badge&logo=apache-kafka&logoColor=white)

### **CI/CD & GitOps**
![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?style=for-the-badge&logo=github-actions&logoColor=white)
![ArgoCD](https://img.shields.io/badge/ArgoCD-EF7B4D?style=for-the-badge&logo=argo&logoColor=white)
![Docker Hub](https://img.shields.io/badge/Docker_Hub-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)

### **Observabilidade & Monitoramento**
![Prometheus](https://img.shields.io/badge/Prometheus-E6522C?style=for-the-badge&logo=prometheus&logoColor=white)
![Grafana](https://img.shields.io/badge/Grafana-F46800?style=for-the-badge&logo=grafana&logoColor=white)
![Jaeger](https://img.shields.io/badge/Jaeger-66CFE3?style=for-the-badge&logo=jaeger&logoColor=white)
![OpenTelemetry](https://img.shields.io/badge/OpenTelemetry-000000?style=for-the-badge&logo=opentelemetry&logoColor=white)
![Fluent Bit](https://img.shields.io/badge/Fluent_Bit-49BDA5?style=for-the-badge&logo=fluentbit&logoColor=white)

### **Ferramentas & UtilitÃ¡rios**
![Helm](https://img.shields.io/badge/Helm-0F1689?style=for-the-badge&logo=helm&logoColor=white)
![NGINX](https://img.shields.io/badge/NGINX-009639?style=for-the-badge&logo=nginx&logoColor=white)
![Linux](https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black)
![Bash](https://img.shields.io/badge/Bash-4EAA25?style=for-the-badge&logo=gnu-bash&logoColor=white)

---

## ğŸ¯ Objetivos do Desafio

### Primeira Semana
- âœ… Rodar aplicaÃ§Ã£o localmente
- âœ… Dockerizar aplicaÃ§Ã£o
- âœ… Provisionar com Terraform + Docker
- âœ… Deploy em Kubernetes local (Kind)
- âœ… Implementar monitoramento (Prometheus + Grafana)

### Segunda Semana
- âœ… Provisionar infraestrutura AWS (VPC, EKS, RDS, Kafka, Redis, OpenSearch)
- âœ… CI/CD com ArgoCD
- âœ… APM e coleta de mÃ©tricas
- âœ… Logs centralizados no OpenSearch
- âœ… OrganizaÃ§Ã£o de IaC
- âœ… DocumentaÃ§Ã£o completa

---

## ğŸ“Š Resultados Obtidos

### âœ… Desafio 1 - AplicaÃ§Ã£o Local
**Status:** ConcluÃ­do

**ImplementaÃ§Ã£o:**
- AplicaÃ§Ã£o Flask rodando localmente
- ConexÃµes com PostgreSQL e Redis funcionando
- MÃ©tricas Prometheus expostas

**Tecnologias:**
- Python 3.12
- Flask 3.0.0
- PostgreSQL
- Redis
- Prometheus Flask Exporter

### âœ… Desafio 2 - DockerizaÃ§Ã£o
**Status:** ConcluÃ­do

**ImplementaÃ§Ã£o:**
- Dockerfile otimizado para produÃ§Ã£o
- Multi-stage build
- UsuÃ¡rio nÃ£o-root
- Health checks nativos
- Docker Compose para ambiente local

**Melhorias Aplicadas:**
- Gunicorn como servidor WSGI
- Workers e threads configurados
- Timeouts adequados
- Imagem slim (Python 3.12-slim)

### âœ… Desafio 3 - Terraform + Docker
**Status:** ConcluÃ­do

**ImplementaÃ§Ã£o:**
- Infraestrutura como cÃ³digo com Terraform
- Provisionamento de containers Docker
- Network isolada
- Volumes persistentes

**Recursos Criados:**
- Container Flask App
- Container PostgreSQL com volume
- Container Redis
- Network bridge customizada

**LocalizaÃ§Ã£o:** `terraform/PrimeiraSemana-Desafio-03/`

### âœ… Desafio 4 - Kubernetes com Kind
**Status:** ConcluÃ­do

**ImplementaÃ§Ã£o:**
- Cluster Kind com 1 control-plane
- NGINX Ingress Controller
- Namespace dedicado (desafio-sre)
- 3 rÃ©plicas da aplicaÃ§Ã£o Flask
- PostgreSQL com PVC
- Redis
- ConfigMaps e Secrets

**Recursos Kubernetes:**
```
NAMESPACE       RECURSO                 REPLICAS    STATUS
desafio-sre     flask-app               3/3         Running
desafio-sre     postgres                1/1         Running
desafio-sre     redis                   1/1         Running
```

**Funcionalidades:**
- Load balancing entre rÃ©plicas
- Health checks (liveness + readiness)
- Resource limits e requests
- Ingress para acesso externo
- Persistent storage para PostgreSQL

**LocalizaÃ§Ã£o:** `PrimeiraSemana-Desafio04/`

### âœ… Desafio 5 - Monitoramento
**Status:** ConcluÃ­do

**ImplementaÃ§Ã£o:**
- Prometheus Operator (kube-prometheus-stack)
- Grafana com dashboards
- ServiceMonitor para coleta de mÃ©tricas
- PrometheusRule com alertas
- MÃ©tricas da aplicaÃ§Ã£o integradas

**Stack de Monitoramento:**
- **Prometheus:** Coleta e armazenamento de mÃ©tricas
- **Grafana:** VisualizaÃ§Ã£o e dashboards
- **Kube State Metrics:** MÃ©tricas do cluster
- **Node Exporter:** MÃ©tricas dos nodes
- **Alertmanager:** Gerenciamento de alertas

**MÃ©tricas Coletadas:**
- RequisiÃ§Ãµes HTTP (total, taxa, duraÃ§Ã£o)
- Erros por status code
- Uso de CPU e memÃ³ria
- MÃ©tricas do Kubernetes
- MÃ©tricas customizadas da aplicaÃ§Ã£o

**Alertas Configurados:**
- FlaskAppDown: AplicaÃ§Ã£o offline >1min
- HighErrorRate: Taxa de erro >5% por 2min
- HighMemoryUsage: MemÃ³ria >80% por 5min

**Acesso:**
- Prometheus: `kubectl port-forward -n monitoring svc/prometheus-server-kube-prom-prometheus 9090:9090`
- Grafana: `kubectl port-forward -n monitoring svc/prometheus-server-grafana 3000:80`


---

## ğŸ—ï¸ Arquitetura Implementada

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Kind Cluster (Docker)                   â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         Namespace: desafio-sre                      â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚ â”‚
â”‚  â”‚  â”‚ Flask    â”‚  â”‚PostgreSQLâ”‚  â”‚  Redis   â”‚        â”‚ â”‚
â”‚  â”‚  â”‚ (3 pods) â”‚  â”‚ (1 pod)  â”‚  â”‚ (1 pod)  â”‚        â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜        â”‚ â”‚
â”‚  â”‚       â”‚             â”‚              â”‚              â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”        â”‚ â”‚
â”‚  â”‚  â”‚         Services (ClusterIP)         â”‚        â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚         Namespace: monitoring                      â”‚â”‚
â”‚  â”‚                                                    â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚â”‚
â”‚  â”‚  â”‚Prometheusâ”‚  â”‚ Grafana  â”‚  â”‚AlertMgr  â”‚       â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚â”‚
â”‚  â”‚       â”‚                                           â”‚â”‚
â”‚  â”‚       â”‚ ServiceMonitor + PrometheusRule          â”‚â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚         Namespace: ingress-nginx                   â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚  â”‚  â”‚      NGINX Ingress Controller                â”‚ â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Arquitetura AWS - Infraestrutura ProduÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          AWS Cloud - us-east-2 (Ohio)                        â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    VPC 10.100.0.0/16 (Multi-AZ)                        â”‚ â”‚
â”‚  â”‚                                                                        â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚ â”‚
â”‚  â”‚  â”‚   us-east-2a             â”‚  â”‚   us-east-2b             â”‚         â”‚ â”‚
â”‚  â”‚  â”‚                          â”‚  â”‚                          â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Public Subnet      â”‚  â”‚  â”‚  â”‚ Public Subnet      â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ NAT Gateway        â”‚  â”‚  â”‚  â”‚ NAT Gateway        â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚           â”‚              â”‚  â”‚           â”‚             â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Private Subnet     â”‚  â”‚  â”‚  â”‚ Private Subnet     â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                    â”‚  â”‚  â”‚  â”‚                    â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”‚ EKS Nodes      â”‚ â”‚  â”‚  â”‚  â”‚ â”‚ EKS Nodes      â”‚ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”‚ - SPOT (t3.*)  â”‚ â”‚  â”‚  â”‚  â”‚ â”‚ - SPOT (t3.*)  â”‚ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”‚ - ON_DEMAND    â”‚ â”‚  â”‚  â”‚  â”‚ â”‚ - ON_DEMAND    â”‚ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                    â”‚  â”‚  â”‚  â”‚                    â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”‚ RDS PostgreSQL â”‚ â”‚  â”‚  â”‚  â”‚ â”‚ RDS Standby    â”‚ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”‚ (Primary)      â”‚â—„â”œâ”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â–ºâ”‚ (Multi-AZ)     â”‚ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                    â”‚  â”‚  â”‚  â”‚                    â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”‚ ElastiCache    â”‚ â”‚  â”‚  â”‚  â”‚ â”‚ ElastiCache    â”‚ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”‚ Redis (Primary)â”‚â—„â”œâ”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â–ºâ”‚ Redis (Replica)â”‚ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                    â”‚  â”‚  â”‚  â”‚                    â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”‚ MSK Kafka      â”‚ â”‚  â”‚  â”‚  â”‚ â”‚ MSK Kafka      â”‚ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”‚ Broker 1       â”‚â—„â”œâ”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â–ºâ”‚ Broker 2       â”‚ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                    â”‚  â”‚  â”‚  â”‚                    â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”‚ OpenSearch     â”‚ â”‚  â”‚  â”‚  â”‚ â”‚ OpenSearch     â”‚ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â”‚ Node 1         â”‚â—„â”œâ”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â–ºâ”‚ Node 2         â”‚ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚         â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ â”‚
â”‚  â”‚                                                                        â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚                    EKS Cluster v1.34                              â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                                                                   â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Namespace: desafio-sre                                       â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                                                              â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ Flask Pod 1  â”‚  â”‚ Flask Pod 2  â”‚  â”‚ Flask Pod 3  â”‚     â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚         â”‚                 â”‚                 â”‚              â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                           â”‚                                 â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                  â”‚ LoadBalancer    â”‚                       â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                  â”‚ Service         â”‚                       â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                              â”‚                                 â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Namespace: argocd                                        â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                                                          â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ ArgoCD       â”‚  â”‚ Repo Server  â”‚  â”‚ Application  â”‚  â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ Server       â”‚  â”‚              â”‚  â”‚ Controller   â”‚  â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                        ServiÃ§os Gerenciados                         â”‚  â”‚
â”‚  â”‚                                                                     â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚  â”‚  â”‚ ECR          â”‚  â”‚ CloudWatch   â”‚  â”‚ IAM Roles    â”‚            â”‚  â”‚
â”‚  â”‚  â”‚ (Registry)   â”‚  â”‚ (Logs/Metrics)â”‚  â”‚ (Security)   â”‚            â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                          CI/CD Pipeline                             â”‚  â”‚
â”‚  â”‚                                                                     â”‚  â”‚
â”‚  â”‚  GitHub â†’ GitHub Actions â†’ Docker Hub â†’ ArgoCD â†’ EKS              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Legenda:
  â—„â”€â–º ReplicaÃ§Ã£o/Failover Multi-AZ
  â”‚   ComunicaÃ§Ã£o entre componentes
  â”Œâ”€â” Componente/ServiÃ§o
```

---

## ğŸ”„ PrÃ³ximos Passos

### AplicaÃ§Ã£o
- **Python 3.12**
- **Flask 3.0.0** - Framework web
- **Gunicorn 21.2.0** - Servidor WSGI
- **PostgreSQL** - Banco de dados relacional
- **Redis** - Cache e sessÃµes
- **Prometheus Flask Exporter** - MÃ©tricas

### Infraestrutura
- **Docker** - ContainerizaÃ§Ã£o
- **Docker Compose** - OrquestraÃ§Ã£o local
- **Terraform** - Infrastructure as Code
- **Kind** - Kubernetes local
- **Kubernetes 1.32** - OrquestraÃ§Ã£o de containers

### Monitoramento
- **Prometheus** - Coleta de mÃ©tricas
- **Grafana** - VisualizaÃ§Ã£o
- **Alertmanager** - Alertas
- **Kube State Metrics** - MÃ©tricas K8s
- **Node Exporter** - MÃ©tricas de sistema

### CI/CD (Preparado)
- **GitHub Actions** - Pipeline CI/CD
- **ArgoCD** - GitOps deployment
- **Docker Hub** - Registry de imagens

---

## ğŸ“ Estrutura do Projeto

```
Desafio-SRE/
â”œâ”€â”€ app/                                    # AplicaÃ§Ã£o Flask
â”‚   â”œâ”€â”€ app.py                             # CÃ³digo da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ requirements.txt                   # DependÃªncias Python
â”‚   â””â”€â”€ Dockerfile                         # Imagem Docker otimizada
â”‚
â”œâ”€â”€ PrimeiraSemana-Desafio04/              # Kubernetes local
â”‚   â”œâ”€â”€ k8s/
â”‚   â”‚   â”œâ”€â”€ Deployments/                   # Manifests da aplicaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ Monitoring/                    # Manifests de monitoramento
â”‚   â”œâ”€â”€ limpar-cluster.sh                  # Script de limpeza
â”‚   â””â”€â”€ recriar-cluster.sh                 # Script de recriaÃ§Ã£o
â”‚
â”‚
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ PrimeiraSemana-Desafio-03/         # Terraform + Docker
â”‚   â””â”€â”€ SegundaSemana/                     # Infraestrutura AWS
â”‚
â”œâ”€â”€ docker-compose.yaml                    # Ambiente local
â””â”€â”€ README.md                              # Este arquivo
```

---

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Docker e Docker Compose
- Kind
- kubectl
- Helm
- Terraform (opcional)

### OpÃ§Ã£o 1: Cluster Completo (Recomendado)
```bash
cd PrimeiraSemana-Desafio04
./recriar-cluster.sh
```

**Tempo:** 10-15 minutos  
**Resultado:** Cluster 100% funcional com monitoramento

### OpÃ§Ã£o 2: Ambiente Local (Docker Compose)
```bash
docker-compose up -d
```

### OpÃ§Ã£o 3: Terraform + Docker
```bash
cd terraform/PrimeiraSemana-Desafio-03
terraform init
terraform apply
```

---

## ğŸ§ª Testes e ValidaÃ§Ã£o

### Testar AplicaÃ§Ã£o
```bash
# Port-forward
kubectl port-forward -n desafio-sre svc/flask-app-service 5000:80

# Endpoints
curl http://localhost:5000/              # Status
curl http://localhost:5000/health        # Health check
curl http://localhost:5000/redis         # Teste Redis
curl http://localhost:5000/postgres      # Teste PostgreSQL
curl http://localhost:5000/metrics       # MÃ©tricas Prometheus
```

### Acessar Monitoramento
```bash
# Prometheus
kubectl port-forward -n monitoring svc/prometheus-server-kube-prom-prometheus 9090:9090

# Grafana
kubectl port-forward -n monitoring svc/prometheus-server-grafana 3000:80
# http://localhost:3000 (admin/admin123)
```

---

## ğŸ“¸ EvidÃªncias Visuais

### Desafio 1 - AplicaÃ§Ã£o Local
![AplicaÃ§Ã£o Rodando Local](Imagens/PrimeiraSemana-Local-Rodando.png)
*AplicaÃ§Ã£o Flask rodando localmente com PostgreSQL e Redis*

![Teste de MÃ©tricas](Imagens/PrimeiraSemana-app-RodandoComPrometheus.png)
*MÃ©tricas Prometheus expostas na aplicaÃ§Ã£o*

### Desafio 2 - Docker Compose
![Docker Compose UP](Imagens/DockerCompose-UP.png)
*Containers rodando via Docker Compose*

![Docker Compose PS](Imagens/DockerComposePS.png)
*Status dos containers*

![Teste Redis](Imagens/curlCompose-redis.png)
*Teste de conexÃ£o com Redis*

### Desafio 3 - Terraform + Docker
![Terraform Apply](Imagens/Desafio-03-Concluido.png)
*Infraestrutura provisionada com Terraform*

![Terraform Docker](Imagens/TerraformDocker.png)
*Containers gerenciados pelo Terraform*

### Desafio 4 - Kubernetes Kind
![CriaÃ§Ã£o Cluster](Imagens/Desafio-04-CriacaoClusterKind.png)
*Cluster Kind sendo criado*

![Cluster UP](Imagens/ClusterKindUP.png)
*Cluster Kind funcionando*

![AtivaÃ§Ã£o Cluster](Imagens/Desafio04-AtivacaoCluster.png)
*Pods da aplicaÃ§Ã£o rodando*

![Carregando Imagem](Imagens/Desafio04-CarregandoImagemNoCluster-app-cluster.png)
*Imagem Docker sendo carregada no Kind*

### Desafio 5 - Monitoramento
![Helm List](Imagens/Desafio05-HelmList.png)
*Prometheus instalado via Helm*

![Pods Monitoring](Imagens/PodsMonitoring.png)
*Pods de monitoramento rodando*

![Prometheus OK](Imagens/Desafio05-Prometheus-OK.png)
*Prometheus coletando mÃ©tricas*

![Teste Prometheus](Imagens/Desafio05-TestePrometheus-OK.png)
*MÃ©tricas da aplicaÃ§Ã£o no Prometheus*

---

## ğŸ“ Aprendizados e Desafios

### Principais Aprendizados

1. **Kubernetes com Kind** - SimulaÃ§Ã£o de cluster local
2. **Observabilidade** - MÃ©tricas, alertas e dashboards
3. **Infrastructure as Code** - Terraform e manifests declarativos
4. **Boas PrÃ¡ticas** - Containers otimizados, health checks, secrets

### Desafios Enfrentados

1. **MÃ©tricas Prometheus** - Porta separada causando erros â†’ SoluÃ§Ã£o: mesma porta
2. **VersÃµes de DependÃªncias** - Flask incompatÃ­vel â†’ SoluÃ§Ã£o: atualizaÃ§Ã£o
3. **Health Checks** - Endpoint inadequado â†’ SoluÃ§Ã£o: `/health` dedicado
4. **Dockerfile** - Rodando como root â†’ SoluÃ§Ã£o: non-root + gunicorn

---

## ğŸ“Š EstatÃ­sticas do Projeto

- **Linhas de CÃ³digo:** ~500
- **Arquivos de ConfiguraÃ§Ã£o:** 30+
- **Containers:** 5
- **Namespaces Kubernetes:** 3
- **MÃ©tricas Coletadas:** 50+
- **Alertas Configurados:** 3
- **DocumentaÃ§Ã£o:** 100+ pÃ¡ginas

---
- [x] Provisionar infraestrutura AWS
---
### âœ… Desafio 6 - Infraestrutura AWS
**Status:** ConcluÃ­do

### âœ… Desafio 7 - CI/CD com ArgoCD
**Status:** ConcluÃ­do

### âœ… Desafio 8 - APM e Coleta de MÃ©tricas
**Status:** ConcluÃ­do


**ImplementaÃ§Ã£o:**
- Infraestrutura completa provisionada na AWS usando Terraform
- Arquitetura modular com remote state isolado por componente
- Multi-AZ para alta disponibilidade
- RegiÃ£o: us-east-2 (Ohio)

**Recursos Provisionados:**

**Networking:**
- VPC 10.100.0.0/16 com 2 Availability Zones (us-east-2a, us-east-2b)
- 2 Subnets pÃºblicas + 2 Subnets privadas
- 2 NAT Gateways para alta disponibilidade
- Internet Gateway
- Route Tables configuradas

**Compute:**
- EKS Cluster v1.34 com control plane gerenciado
- 3 Node Groups:
  - spot_1: 2 nodes t3.medium/t3a.medium (SPOT)
  - spot_2: 2 nodes t3.large/t3a.large (SPOT)
  - on_demand: 1 node t3.medium (ON_DEMAND)
- Auto-scaling configurado (5-11 nodes)
- IAM Roles com polÃ­ticas de menor privilÃ©gio

**Databases:**
- RDS PostgreSQL 17.6 (db.t3.micro)
- Multi-AZ para failover automÃ¡tico
- Backup automatizado
- Criptografia at-rest habilitada

**Cache:**
- ElastiCache Redis 7.0 (cache.t3.micro)
- ReplicaÃ§Ã£o Multi-AZ
- Automatic failover habilitado

**Messaging:**
- MSK (Managed Kafka) 3.5.1
- 2 brokers kafka.t3.small
- Multi-AZ deployment
- Criptografia in-transit e at-rest

**Search & Analytics:**
- OpenSearch 2.11 (t3.small.search)
- 2 nodes para alta disponibilidade
- Fine-grained access control
- Encryption at-rest e node-to-node

**Container Registry:**
- ECR (Elastic Container Registry)
- Image scanning habilitado
- Lifecycle policy (manter Ãºltimas 10 imagens)

**SeguranÃ§a:**
- Security Groups isolados por serviÃ§o
- Criptografia habilitada em todos os recursos
- IAM Roles com polÃ­ticas especÃ­ficas
- Secrets gerenciados pela AWS
- VPC endpoints para serviÃ§os AWS

**Observabilidade:**
- EKS Control Plane Logs habilitados
- CloudWatch Logs integrado
- Tags padronizadas em todos os recursos

**Infraestrutura como CÃ³digo:**
- 10 mÃ³dulos Terraform independentes
- Remote state no S3 com versionamento
- Backend isolado por mÃ³dulo
- VariÃ¡veis centralizadas
- Tags padrÃ£o aplicadas automaticamente

**MÃ³dulos Terraform:**
```
00-s3_remote_state/    # Bucket S3 para remote state
01-vpc/                # VPC + Subnets + NAT Gateways
02-security_group/     # Security Groups isolados
03-iam/                # IAM Roles para EKS
04-eks/                # EKS Cluster v1.34
05-node_groups/        # 3 Node Groups (2 SPOT + 1 ON_DEMAND)
06-rds/                # PostgreSQL Multi-AZ
07-kafka/              # MSK (Kafka) 2 brokers
08-redis/              # ElastiCache Redis replicado
09-opensearch/         # OpenSearch 2 nodes
10-ecr/                # Container Registry
11-observability       # Observabilidade
```

**Desafios TÃ©cnicos Superados:**
1. **Capacidade SPOT:** InstÃ¢ncias t3a.medium indisponÃ­veis em us-east-1a â†’ MigraÃ§Ã£o para us-east-2 (us-east-2a, us-east-2b)
2. **Naming OpenSearch:** Domain name com underscores invÃ¡lido â†’ ImplementaÃ§Ã£o de funÃ§Ã£o replace() para sanitizaÃ§Ã£o
3. **Tags Padronizadas:** RepetiÃ§Ã£o manual de tags â†’ ImplementaÃ§Ã£o de default_tags no provider AWS
4. **ModularizaÃ§Ã£o:** DependÃªncias entre mÃ³dulos â†’ Remote state data sources para comunicaÃ§Ã£o

**Boas PrÃ¡ticas Implementadas:**
- âœ… Infraestrutura modular e reutilizÃ¡vel
- âœ… Remote state isolado por componente
- âœ… Multi-AZ em todos os serviÃ§os crÃ­ticos
- âœ… Criptografia por padrÃ£o
- âœ… Security Groups com menor privilÃ©gio
- âœ… Auto-scaling configurado
- âœ… Backup automatizado
- âœ… Tags consistentes para governanÃ§a
- âœ… DocumentaÃ§Ã£o inline nos mÃ³dulos

**Custo Estimado Mensal:**
- VPC (NAT Gateways): ~$65
- EKS Control Plane: ~$73
- EC2 Nodes (5-11 instances): ~$80-120
- RDS PostgreSQL: ~$30
- MSK (Kafka): ~$150
- ElastiCache Redis: ~$25
- OpenSearch: ~$80
- **Total:** ~$500-550/mÃªs

**LocalizaÃ§Ã£o:** `terraform/SegundaSemana/`

**Tempo de Provisionamento:** ~45 minutos

**ValidaÃ§Ã£o:**
```bash
# Configurar kubectl
aws eks update-kubeconfig --name desafio-sre-junior-eks --region us-east-2

# Verificar nodes
kubectl get nodes

# Verificar recursos AWS
aws eks describe-cluster --name desafio-sre-junior-eks --region us-east-2
aws rds describe-db-instances --region us-east-2
aws elasticache describe-cache-clusters --region us-east-2
```

---
### âœ… Desafio 7 - CI/CD com ArgoCD ğŸš€
**Status:** ConcluÃ­do

![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?style=for-the-badge&logo=github-actions&logoColor=white)
![ArgoCD](https://img.shields.io/badge/ArgoCD-EF7B4D?style=for-the-badge&logo=argo&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white)
![AWS](https://img.shields.io/badge/AWS-FF9900?style=for-the-badge&logo=amazon-aws&logoColor=white)
![Flask](https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white)

**ImplementaÃ§Ã£o:**
- Pipeline CI/CD completo com GitHub Actions e ArgoCD
- GitOps deployment automatizado
- Build e push automÃ¡tico de imagens Docker
- SincronizaÃ§Ã£o automÃ¡tica de manifests Kubernetes
- AplicaÃ§Ã£o rodando em EKS com 3 rÃ©plicas

**ğŸ› ï¸ Stack TecnolÃ³gica:**
- ğŸ™ **GitHub Actions** - CI/CD Pipeline
- ğŸ”„ **ArgoCD** - GitOps Deployment
- ğŸ³ **Docker Hub** - Container Registry
- â˜¸ï¸ **Kubernetes** - OrquestraÃ§Ã£o
- ğŸŒ **AWS Load Balancer** - ExposiÃ§Ã£o externa
- ğŸ“Š **Prometheus** - MÃ©tricas integradas

**ğŸ”§ Componentes Detalhados:**

**GitHub Actions Pipeline:**
- ğŸ“ **Workflow:** `.github/workflows/build-deploy.yml`
- ğŸ¯ **Trigger:** Push em `main` com mudanÃ§as em `app/**`
- ğŸ—ï¸ **Build:** Imagem Docker otimizada multi-stage
- ğŸ“¤ **Push:** Docker Hub `crfjunior65/flask-app:latest`
- â±ï¸ **Tempo:** ~2-3 minutos
- ğŸ” **ValidaÃ§Ã£o:** Testes de sintaxe e build

**ArgoCD GitOps:**
- ğŸ“¦ **Namespace:** `argocd`
- ğŸ¯ **Application:** `desafio-sre-app`
- ğŸ“‚ **Source:** RepositÃ³rio Git (branch `main`)
- ğŸ“ **Path:** `terraform/SegundaSemana/k8s-manifests/`
- ğŸ”„ **Sync Policy:** AutomÃ¡tico com self-heal
- ğŸ§¹ **Prune:** Habilitado para limpeza automÃ¡tica
- ğŸ” **RBAC:** Configurado com menor privilÃ©gio

**Kubernetes Manifests:**
- ğŸš€ **Deployment:** 3 rÃ©plicas Flask com rolling updates
- ğŸŒ **Service:** LoadBalancer para acesso externo
- âš™ï¸ **ConfigMap:** Endpoints RDS, Redis, Kafka, OpenSearch
- ğŸ” **Secret:** Credenciais PostgreSQL criptografadas
- ğŸ¥ **Health Checks:** Liveness e readiness probes
- ğŸ“Š **Resources:** CPU/Memory limits e requests

**ğŸ”„ Fluxo CI/CD Completo:**
```
1. ğŸ‘¨â€ğŸ’» Developer push cÃ³digo â†’ GitHub
2. ğŸ” GitHub Actions detecta mudanÃ§a em app/**
3. ğŸ—ï¸ Build da imagem Docker multi-stage
4. ğŸ§ª ExecuÃ§Ã£o de testes automatizados
5. ğŸ“¤ Push para Docker Hub (crfjunior65/flask-app:latest)
6. ğŸ‘ï¸ ArgoCD detecta mudanÃ§a no Git repository
7. ğŸ”„ ArgoCD sincroniza manifests com EKS cluster
8. â˜¸ï¸ Kubernetes executa rolling update dos pods
9. ğŸŒ LoadBalancer roteia trÃ¡fego para novos pods
10. ğŸ“Š MÃ©tricas disponÃ­veis no Prometheus
```

**ğŸ“¦ Recursos Deployados:**
```
NAMESPACE       RECURSO                 REPLICAS    STATUS      FUNCIONALIDADE
desafio-sre     flask-app               3/3         Running     AplicaÃ§Ã£o principal
desafio-sre     flask-app-service       1           Active      LoadBalancer AWS
desafio-sre     flask-config            1           Active      ConfiguraÃ§Ãµes
desafio-sre     postgres-secret         1           Active      Credenciais DB
```

**ğŸŒ Endpoints da AplicaÃ§Ã£o:**
- ğŸ  `/` - Status da aplicaÃ§Ã£o e health check bÃ¡sico
- ğŸ¥ `/health` - Health check detalhado (DB + Redis)
- ğŸ“‹ `/version` - VersÃ£o, deployed_by e informaÃ§Ãµes build
- ğŸ”´ `/redis` - Teste conexÃ£o Redis com operaÃ§Ãµes R/W
- ğŸ˜ `/postgres` - Teste conexÃ£o PostgreSQL com queries
- ğŸ“Š `/metrics` - MÃ©tricas Prometheus (HTTP, DB, Redis)
- ğŸ§ª `/testes` - Endpoint para validaÃ§Ã£o de funcionalidades

**â±ï¸ Performance do Pipeline:**
- ğŸ—ï¸ **GitHub Actions:** 2-3 minutos (build + push)
- ğŸ”„ **ArgoCD Sync:** 1-2 minutos (detecÃ§Ã£o + sync)
- â˜¸ï¸ **Kubernetes Rollout:** 1-2 minutos (rolling update)
- ğŸŒ **LoadBalancer Update:** 30-60 segundos
- **âš¡ Total:** 4-7 minutos (zero downtime)

**ğŸ” ValidaÃ§Ã£o e Monitoramento:**
```bash
# Verificar ArgoCD Application
kubectl get application -n argocd desafio-sre-app -o wide

# Verificar pods e status
kubectl get pods -n desafio-sre -o wide
kubectl describe deployment -n desafio-sre flask-app

# Obter URL do LoadBalancer
kubectl get svc -n desafio-sre flask-app-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'

# Testar todos os endpoints
curl http://<LOAD_BALANCER_URL>/health
curl http://<LOAD_BALANCER_URL>/version
curl http://<LOAD_BALANCER_URL>/redis
curl http://<LOAD_BALANCER_URL>/postgres
curl http://<LOAD_BALANCER_URL>/metrics

# Verificar logs da aplicaÃ§Ã£o
kubectl logs -n desafio-sre -l app=flask-app --tail=100 -f

# Monitorar ArgoCD sync status
kubectl get application -n argocd desafio-sre-app -w
```

**ğŸ“ Estrutura de Arquivos:**
```
.github/workflows/
â””â”€â”€ build-deploy.yml              # Pipeline CI/CD

terraform/SegundaSemana/
â”œâ”€â”€ k8s-manifests/
â”‚   â”œâ”€â”€ deployment.yaml           # Flask app deployment
â”‚   â”œâ”€â”€ service.yaml              # LoadBalancer service
â”‚   â”œâ”€â”€ configmap.yaml            # ConfiguraÃ§Ãµes aplicaÃ§Ã£o
â”‚   â””â”€â”€ secret.yaml               # Credenciais PostgreSQL
â”œâ”€â”€ k8s-argocd/
â”‚   â””â”€â”€ application.yaml          # ArgoCD application
â””â”€â”€ argocd-application.yaml       # ArgoCD app definition
```

**ğŸš¨ Desafios TÃ©cnicos Superados:**

1. **ğŸ”— Symlinks no RepositÃ³rio Git**
   - **âŒ Problema:** ArgoCD bloqueou sync devido a symlinks de venv Python
   - **âš ï¸ Erro:** "Illegal filepath in repo" - security violation
   - **âœ… SoluÃ§Ã£o:** `git rm -r --cached venv/` + `.gitignore` atualizado
   - **ğŸ“š Aprendizado:** Python venv nunca deve ser commitado

2. **ğŸ·ï¸ Nome Incorreto da Imagem Docker**
   - **âŒ Problema:** Workflow usava `desafio-sre-app` mas deveria ser `flask-app`
   - **ğŸ’¥ Impacto:** Imagens enviadas para repositÃ³rio errado no Docker Hub
   - **âœ… SoluÃ§Ã£o:** PadronizaÃ§Ã£o `IMAGE_NAME` no workflow e manifests
   - **ğŸ“š Aprendizado:** Definir naming convention desde o inÃ­cio

3. **âš¡ FunÃ§Ã£o Duplicada no Flask**
   - **âŒ Problema:** Duas funÃ§Ãµes `version()` causando `AssertionError`
   - **ğŸ’¥ Erro:** "View function mapping is overwriting an existing endpoint"
   - **âœ… SoluÃ§Ã£o:** Renomear segunda funÃ§Ã£o para `testes()`
   - **ğŸ“š Aprendizado:** ValidaÃ§Ã£o local antes de push obrigatÃ³ria

4. **ğŸ’¾ Cache do ArgoCD Repo Server**
   - **âŒ Problema:** ArgoCD mantinha cache com symlinks invÃ¡lidos
   - **âœ… SoluÃ§Ã£o:** `kubectl delete pod -n argocd -l app.kubernetes.io/name=argocd-repo-server`
   - **ğŸ“š Aprendizado:** Cache management Ã© crÃ­tico em GitOps

5. **ğŸ” Gerenciamento de Secrets**
   - **âŒ Problema:** Secret PostgreSQL nÃ£o criado automaticamente
   - **âœ… SoluÃ§Ã£o:** Manifest dedicado + ArgoCD sync
   - **ğŸ“š Aprendizado:** Secrets devem ser tratados separadamente

**âœ… Boas PrÃ¡ticas DevOps Implementadas:**
- ğŸ”„ **GitOps:** Manifests versionados com single source of truth
- ğŸ·ï¸ **Imagens ImutÃ¡veis:** Tags com SHA do commit para rastreabilidade
- ğŸ¥ **Health Checks:** Liveness, readiness e startup probes
- ğŸ”„ **Rolling Updates:** Zero downtime deployments com strategy
- ğŸ”§ **Self-Healing:** ArgoCD reverte mudanÃ§as manuais automaticamente
- ğŸ“Š **Observabilidade:** MÃ©tricas Prometheus integradas nativamente
- ğŸ” **Security:** Secrets management separado do cÃ³digo
- ğŸ“ **Documentation:** Manifests autodocumentados com annotations
- ğŸ—ï¸ **Infrastructure as Code:** Tudo versionado e reproduzÃ­vel

**ğŸ”® Roadmap de Melhorias:**
- [ ] ğŸ·ï¸ Implementar semantic versioning (v1.0.0) com git tags
- [ ] ğŸ§ª Adicionar testes automatizados (unit + integration)
- [ ] ğŸŒ Implementar multi-environment (dev, staging, prod)
- [ ] ğŸ“¢ Configurar notificaÃ§Ãµes ArgoCD (Slack/Teams/Email)
- [ ] ğŸ›¡ï¸ Adicionar security scanning (Trivy/Snyk) no pipeline
- [ ] ğŸ“Š Implementar deployment metrics e SLI/SLO
- [ ] ğŸ”„ Configurar blue-green deployments para releases crÃ­ticas
- [ ] ğŸ¯ Implementar feature flags para releases graduais
- Application: `desafio-sre-app`
- Source: RepositÃ³rio Git (branch `main`)
- Path: `terraform/SegundaSemana/k8s-manifests/`
- Sync Policy: AutomÃ¡tico
- Self-Heal: Habilitado
- Prune: Habilitado

**Manifests Kubernetes:**
- **Deployment:** 3 rÃ©plicas Flask com health checks
- **Service:** LoadBalancer para acesso externo
- **ConfigMap:** Endpoints RDS, Redis, Kafka, OpenSearch
- **Secret:** Senha do PostgreSQL

**Fluxo CI/CD:**
```
1. Developer push cÃ³digo â†’ GitHub
2. GitHub Actions detecta mudanÃ§a em app/**
3. Build da imagem Docker
4. Push para Docker Hub (crfjunior65/flask-app:latest)
5. ArgoCD detecta mudanÃ§a no Git
6. ArgoCD sincroniza manifests com EKS
7. Kubernetes faz rolling update dos pods
8. LoadBalancer roteia trÃ¡fego para novos pods
```

**Recursos Deployados:**
```
NAMESPACE       RECURSO                 REPLICAS    STATUS
desafio-sre     flask-app               3/3         Running
desafio-sre     flask-app-service       1           LoadBalancer
desafio-sre     flask-config            1           ConfigMap
desafio-sre     postgres-secret         1           Secret
```

**Endpoints da AplicaÃ§Ã£o:**
- `/` - Status da aplicaÃ§Ã£o
- `/health` - Health check
- `/version` - VersÃ£o e deployed_by
- `/redis` - Teste conexÃ£o Redis
- `/postgres` - Teste conexÃ£o PostgreSQL
- `/metrics` - MÃ©tricas Prometheus

**Tempo de Deploy Completo:**
- GitHub Actions: 2-3 minutos
- ArgoCD Sync: 1-2 minutos
- Kubernetes Rollout: 1-2 minutos
- **Total:** 4-7 minutos

**ValidaÃ§Ã£o:**
```bash
# Verificar ArgoCD Application
kubectl get application -n argocd desafio-sre-app

# Verificar pods
kubectl get pods -n desafio-sre

# Obter URL do LoadBalancer
kubectl get svc -n desafio-sre flask-app-service

# Testar endpoints
curl http://<LOAD_BALANCER_URL>/health
curl http://<LOAD_BALANCER_URL>/version
```

**LocalizaÃ§Ã£o:**
- Workflow: `.github/workflows/build-deploy.yml`
- ArgoCD App: `terraform/SegundaSemana/argocd-application.yaml`
- Manifests: `terraform/SegundaSemana/k8s-manifests/`

**Desafios Enfrentados:**

1. **Symlinks no RepositÃ³rio Git**
   - **Problema:** ArgoCD bloqueou sync devido a symlinks de venv Python
   - **Erro:** "Illegal filepath in repo"
   - **SoluÃ§Ã£o:** Remover diretÃ³rios com symlinks do Git usando `git rm -r --cached`
   - **Aprendizado:** Python venv deve estar sempre no `.gitignore`

2. **Nome Incorreto da Imagem Docker**
   - **Problema:** Workflow usava `desafio-sre-app` mas deveria ser `flask-app`
   - **Impacto:** Imagens sendo enviadas para repositÃ³rio errado no Docker Hub
   - **SoluÃ§Ã£o:** Corrigir `IMAGE_NAME` no workflow e deployment manifest
   - **Aprendizado:** Padronizar nomes dsesde o inÃ­cio do projeto

3. **FunÃ§Ã£o Duplicada no CÃ³digo**
   - **Problema:** Duas funÃ§Ãµes com nome `version()` causando `AssertionError`
   - **Erro:** "View function mapping is overwriting an existing endpoint"
   - **SoluÃ§Ã£o:** Renomear segunda funÃ§Ã£o para `testes()`
   - **Aprendizado:** Validar cÃ³digo localmente antes de push

4. **Cache do ArgoCD Repo Server**
   - **Problema:** ArgoCD mantinha cache do repositÃ³rio com symlinks
   - **SoluÃ§Ã£o:** Restart do pod `argocd-repo-server` para limpar cache
   - **Comando:** `kubectl delete pod -n argocd -l app.kubernetes.io/name=argocd-repo-server`

5. **ConfiguraÃ§Ã£o de Secrets**
   - **Problema:** Secret do PostgreSQL nÃ£o criado automaticamente
   - **SoluÃ§Ã£o:** Criar manualmente via kubectl ou incluir no ArgoCD
   - **Aprendizado:** Secrets sensÃ­veis devem ser gerenciados separadamente

**Boas PrÃ¡ticas Implementadas:**
- âœ… GitOps: Manifests versionados no Git
- âœ… Imagens imutÃ¡veis: Tag com SHA do commit
- âœ… Health checks: Liveness e readiness probes
- âœ… Rolling updates: Zero downtime deployments
- âœ… Self-healing: ArgoCD reverte mudanÃ§as manuais
- âœ… Observabilidade: MÃ©tricas Prometheus expostas
- âœ… Secrets management: Separado do cÃ³digo

**Melhorias Futuras:**
- [ ] Implementar tags semÃ¢nticas (v1.0.0) ao invÃ©s de `latest`
- [ ] Adicionar testes automatizados no pipeline
- [ ] Implementar ambientes (dev, staging, prod)
- [ ] Configurar notificaÃ§Ãµes do ArgoCD (Slack/Email)
- [ ] Adicionar anÃ¡lise de seguranÃ§a de imagens (Trivy)

---

### âœ… Desafio 8 - APM e Coleta de MÃ©tricas ğŸ“Š
**Status:** ConcluÃ­do

![Prometheus](https://img.shields.io/badge/Prometheus-E6522C?style=for-the-badge&logo=prometheus&logoColor=white)
![Grafana](https://img.shields.io/badge/Grafana-F46800?style=for-the-badge&logo=grafana&logoColor=white)
![Jaeger](https://img.shields.io/badge/Jaeger-66CFE3?style=for-the-badge&logo=jaeger&logoColor=white)
![OpenTelemetry](https://img.shields.io/badge/OpenTelemetry-000000?style=for-the-badge&logo=opentelemetry&logoColor=white)
![Fluent Bit](https://img.shields.io/badge/Fluent_Bit-49BDA5?style=for-the-badge&logo=fluentbit&logoColor=white)
![Elasticsearch](https://img.shields.io/badge/Elasticsearch-005571?style=for-the-badge&logo=elasticsearch&logoColor=white)
![OpenSearch](https://img.shields.io/badge/OpenSearch-005EB8?style=for-the-badge&logo=opensearch&logoColor=white)

**ImplementaÃ§Ã£o:**
- Stack completa de observabilidade implementada no EKS
- Coleta de mÃ©tricas de aplicaÃ§Ã£o e infraestrutura
- Distributed tracing para APM
- Logs centralizados no OpenSearch existente
- Dashboards e alertas configurados

**Componentes Implementados:**

**Prometheus Stack (kube-prometheus-stack):**
- **Prometheus Server:** Coleta e armazenamento de mÃ©tricas (retenÃ§Ã£o 7d, 10Gi)
- **Grafana:** Interface visual com dashboards (LoadBalancer, senha: admin123)
- **AlertManager:** Gerenciamento de alertas (2Gi storage)
- **Node Exporter:** MÃ©tricas dos nodes (CPU, memÃ³ria, disco)
- **Kube State Metrics:** MÃ©tricas do Kubernetes (pods, deployments)

**Jaeger (Distributed Tracing):**
- **Jaeger Collector:** Recebe traces das aplicaÃ§Ãµes (ClusterIP:14250/14268)
- **Jaeger Query:** Interface web para visualizar traces (LoadBalancer:16686)
- **Jaeger Agent:** DaemonSet que coleta traces localmente
- **Elasticsearch:** Armazenamento dos traces (5Gi storage)

**OpenTelemetry Collector:**
- **Modo DaemonSet:** Coleta telemetria de todos os nodes
- **Receivers:** OTLP (gRPC:4317, HTTP:4318) e Prometheus
- **Exporters:** Prometheus (mÃ©tricas) e Jaeger (traces)
- **Processors:** Batch processing e memory limiter (512MB)

**Fluent Bit (Log Collection):**
- **DaemonSet:** Coleta logs de containers e sistema
- **Kubernetes Integration:** Parsing automÃ¡tico de logs K8s
- **OpenSearch Output:** Envio para cluster OpenSearch existente
- **IAM Role:** PermissÃµes para escrita no OpenSearch

**Namespaces Criados:**
```
NAMESPACE       COMPONENTES
monitoring      Prometheus, Grafana, AlertManager, OpenTelemetry
tracing         Jaeger (Collector, Query, Agent, Elasticsearch)
logging         Fluent Bit DaemonSet
```

**MÃ©tricas Coletadas:**
- **AplicaÃ§Ã£o Flask:** Requests HTTP, latÃªncia, erros, mÃ©tricas customizadas
- **Kubernetes:** Pods, deployments, services, nodes, recursos
- **Infraestrutura:** CPU, memÃ³ria, disco, network dos nodes
- **Banco de Dados:** ConexÃµes, queries (via instrumentaÃ§Ã£o)
- **Cache Redis:** OperaÃ§Ãµes, latÃªncia, hit rate

**Dashboards Grafana:**
- **Kubernetes Cluster Monitoring (ID: 7249):** Overview do cluster
- **Kubernetes Pod Monitoring (ID: 6417):** MÃ©tricas de pods
- **Flask App Monitoring (ID: 3681):** MÃ©tricas da aplicaÃ§Ã£o
- **Dashboards customizados:** ConfigurÃ¡veis via providers

**Alertas Configurados:**
- **High CPU Usage:** >80% por 5 minutos
- **High Memory Usage:** >85% por 5 minutos
- **Pod Restart Loop:** >3 restarts em 10 minutos
- **Application Errors:** >5% error rate por 2 minutos
- **Database Connection Issues:** Falha de conexÃ£o

**Logs Centralizados:**
- **Ãndices OpenSearch:**
  - `fluentbit-k8s`: Logs de containers Kubernetes
  - `fluentbit-host`: Logs de sistema dos nodes
- **Parsing AutomÃ¡tico:** JSON logs, multiline, Kubernetes metadata
- **Filtros:** Namespace, pod, container, severity level

**InstrumentaÃ§Ã£o da AplicaÃ§Ã£o:**
- **Arquivo Base:** `app/app.py` (mÃ©tricas Prometheus existentes)
- **VersÃ£o Instrumentada:** `app/app-instrumented.py` (OpenTelemetry opcional)
- **DependÃªncias APM:** `app/requirements-observability.txt`
- **Traces DistribuÃ­dos:** Spans para DB, Redis, HTTP requests

**Arquitetura de Observabilidade:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          EKS Cluster (us-east-2)                             â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Namespace: monitoring                                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚ â”‚
â”‚  â”‚  â”‚ Prometheus   â”‚  â”‚   Grafana    â”‚  â”‚ AlertManager â”‚                â”‚ â”‚
â”‚  â”‚  â”‚ (MÃ©tricas)   â”‚  â”‚(Dashboards)  â”‚  â”‚  (Alertas)   â”‚                â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚ â”‚
â”‚  â”‚         â”‚                                                              â”‚ â”‚
â”‚  â”‚         â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚ â”‚
â”‚  â”‚         â””â–ºâ”‚ Node Exporterâ”‚  â”‚OpenTelemetry â”‚                          â”‚ â”‚
â”‚  â”‚           â”‚ (Nodes)      â”‚  â”‚ Collector    â”‚                          â”‚ â”‚
â”‚  â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Namespace: tracing                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚ â”‚
â”‚  â”‚  â”‚    Jaeger    â”‚  â”‚ Elasticsearchâ”‚  â”‚  Jaeger UI   â”‚                â”‚ â”‚
â”‚  â”‚  â”‚  (Collector) â”‚  â”‚  (Storage)   â”‚  â”‚ (Interface)  â”‚                â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Namespace: logging                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚ â”‚
â”‚  â”‚  â”‚  Fluent Bit  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”¤
â”‚  â”‚  â”‚ (DaemonSet)  â”‚                                                     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OpenSearch (us-east-2) - JÃ¡ Existente                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚  â”‚ OpenSearch   â”‚  â”‚ OpenSearch   â”‚                                        â”‚
â”‚  â”‚   Node 1     â”‚  â”‚   Node 2     â”‚                                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ValidaÃ§Ã£o e Acesso:**
```bash
# Verificar pods de observabilidade
kubectl get pods -n monitoring
kubectl get pods -n tracing
kubectl get pods -n logging

# Acessar Grafana
kubectl port-forward -n monitoring svc/prometheus-stack-grafana 3000:80
# http://localhost:3000 (admin/admin123)

# Acessar Jaeger
kubectl port-forward -n tracing svc/jaeger-query 16686:16686
# http://localhost:16686

# Acessar Prometheus
kubectl port-forward -n monitoring svc/prometheus-stack-kube-prom-prometheus 9090:9090
# http://localhost:9090

# Verificar logs no OpenSearch
# Acessar via OpenSearch Dashboards (configurado no Desafio 6)
```

**LocalizaÃ§Ã£o:**
- MÃ³dulo Terraform: `terraform/SegundaSemana/11-observability/`
- Script de Deploy: `terraform/SegundaSemana/deploy-observability.sh`
- InstrumentaÃ§Ã£o: `app/app-instrumented.py` (opcional)
- DependÃªncias APM: `app/requirements-observability.txt`

**Custo Adicional Estimado:**
- **EBS Volumes (Prometheus/Grafana/Jaeger):** ~$20/mÃªs
- **LoadBalancers (Grafana/Jaeger):** ~$20/mÃªs
- **Compute overhead:** ~$5/mÃªs
- **Total adicional:** ~$45/mÃªs

**Boas PrÃ¡ticas Implementadas:**
- âœ… Observabilidade completa: MÃ©tricas, logs e traces
- âœ… Dashboards padronizados da comunidade
- âœ… Alertas proativos para problemas crÃ­ticos
- âœ… Logs centralizados com parsing automÃ¡tico
- âœ… IAM roles com menor privilÃ©gio
- âœ… Persistent storage para dados histÃ³ricos
- âœ… Service discovery automÃ¡tico
- âœ… InstrumentaÃ§Ã£o nÃ£o-intrusiva

**Melhorias Futuras:**
- [ ] Implementar distributed tracing na aplicaÃ§Ã£o Flask
- [ ] Configurar dashboards customizados para mÃ©tricas de negÃ³cio
- [ ] Adicionar alertas via Slack/Email
- [ ] Implementar SLI/SLO monitoring
- [ ] Configurar retention policies otimizadas

---

### Segunda Semana
- âœ… Deploy com ArgoCD
- âœ… Implementar APM
- âœ… Centralizar logs no OpenSearch
- âœ… DocumentaÃ§Ã£o completa

---

---

## ğŸ‘¤ Autor

**Junior Fernandes**  
SRE / DevOps - ElvenWorks

---

**Ãšltima atualizaÃ§Ã£o:** 13/12/2024  
**VersÃ£o:** 1.3  
**Status:** Desafios 7 e 8 ConcluÃ­dos âœ…
